{"input_size": 46776, "n_layers": 1, "encoded_size": 64, "hidden_size": 256, "batch_size": 1182, "drop_prob": 0.5, "fnn_hidden_size": 40, "fnn_number_layers": 2, "num_classes": [2, 2, 4, 3, 2, 3], "fnn_num_epoch": 100, "fnn_learning_rate": 0.05}